{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%%writefile daily_loader.py\n",
        "\n",
        "import os\n",
        "import re\n",
        "import pandas as pd\n",
        "from sqlalchemy import create_engine, text\n",
        "from sqlalchemy import text\n",
        "\n",
        "# === CONFIGURATION ===\n",
        "DATA_LAKE_PATH = \"data_lake\"\n",
        "DB_URL = \"sqlite:///my_database.db\"\n",
        "engine = create_engine(DB_URL)\n",
        "\n",
        "# === DATE EXTRACTORS ===\n",
        "def extract_date_from_filename(filename):\n",
        "    match = re.search(r'(\\d{8})', filename)\n",
        "    if match:\n",
        "        return pd.to_datetime(match.group(1), format='%Y%m%d').strftime(\"%Y-%m-%d\")\n",
        "    return None\n",
        "\n",
        "def extract_datekey_from_filename(filename):\n",
        "    match = re.search(r'(\\d{8})', filename)\n",
        "    if match:\n",
        "        return match.group(1)\n",
        "    return None\n",
        "\n",
        "# === TRUNCATE TABLE ===\n",
        "def truncate_table(table_name):\n",
        "    try:\n",
        "        with engine.begin() as conn:\n",
        "            conn.execute(text(f\"DELETE FROM {table_name}\"))  # ✅ wrap with text()\n",
        "            print(f\"✅ Truncated {table_name}\")\n",
        "    except Exception as e:\n",
        "        print(f\"⚠️ Could not truncate {table_name}: {e}\")\n",
        "\n",
        "\n",
        "# === CATEGORIZE FILES ===\n",
        "cust_mstr_files = []\n",
        "master_child_files = []\n",
        "ecom_order_files = []\n",
        "\n",
        "os.makedirs(DATA_LAKE_PATH, exist_ok=True)\n",
        "\n",
        "for file in os.listdir(DATA_LAKE_PATH):\n",
        "    if file.startswith(\"CUST_MSTR_\"):\n",
        "        cust_mstr_files.append(file)\n",
        "    elif file.startswith(\"master_child_export-\"):\n",
        "        master_child_files.append(file)\n",
        "    elif file.startswith(\"H_ECOM_ORDER\"):\n",
        "        ecom_order_files.append(file)\n",
        "\n",
        "# === LOAD CUST_MSTR FILES ===\n",
        "if cust_mstr_files:\n",
        "    try:\n",
        "        truncate_table(\"CUST_MSTR\")\n",
        "    except Exception as e:\n",
        "        print(\"⚠️ Could not truncate CUST_MSTR:\", e)\n",
        "\n",
        "    for file in cust_mstr_files:\n",
        "        date_val = extract_date_from_filename(file)\n",
        "        df = pd.read_csv(os.path.join(DATA_LAKE_PATH, file))\n",
        "        df[\"Date\"] = date_val\n",
        "        df.to_sql(\"CUST_MSTR\", engine, index=False, if_exists=\"append\")\n",
        "        print(f\"✅ Loaded {file} into CUST_MSTR\")\n",
        "\n",
        "# === LOAD master_child_export FILES ===\n",
        "if master_child_files:\n",
        "    try:\n",
        "        truncate_table(\"master_child\")\n",
        "    except Exception as e:\n",
        "        print(\"⚠️ Could not truncate master_child:\", e)\n",
        "\n",
        "    for file in master_child_files:\n",
        "        date_val = extract_date_from_filename(file)\n",
        "        date_key = extract_datekey_from_filename(file)\n",
        "        df = pd.read_csv(os.path.join(DATA_LAKE_PATH, file))\n",
        "        df[\"Date\"] = date_val\n",
        "        df[\"DateKey\"] = date_key\n",
        "        df.to_sql(\"master_child\", engine, index=False, if_exists=\"append\")\n",
        "        print(f\"✅ Loaded {file} into master_child\")\n",
        "\n",
        "# === LOAD H_ECOM_ORDER FILES ===\n",
        "if ecom_order_files:\n",
        "    try:\n",
        "        truncate_table(\"H_ECOM_Orders\")\n",
        "    except Exception as e:\n",
        "        print(\"⚠️ Could not truncate H_ECOM_Orders:\", e)\n",
        "\n",
        "    for file in ecom_order_files:\n",
        "        df = pd.read_csv(os.path.join(DATA_LAKE_PATH, file))\n",
        "        df.to_sql(\"H_ECOM_Orders\", engine, index=False, if_exists=\"append\")\n",
        "        print(f\"✅ Loaded {file} into H_ECOM_Orders\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7I0Tr2i-bU9V",
        "outputId": "7bf28459-6103-4fcf-9768-bf42689792ff"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting daily_loader.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs(\"data_lake\", exist_ok=True)\n",
        "\n",
        "with open(\"data_lake/CUST_MSTR_20191112.csv\", \"w\") as f:\n",
        "    f.write(\"CustomerID,Name\\n1,Alice\\n2,Bob\")\n",
        "\n",
        "with open(\"data_lake/master_child_export-20191112.csv\", \"w\") as f:\n",
        "    f.write(\"ParentID,ChildID\\n100,200\\n101,201\")\n",
        "\n",
        "with open(\"data_lake/H_ECOM_ORDER.csv\", \"w\") as f:\n",
        "    f.write(\"OrderID,Amount\\n5001,250.75\\n5002,199.99\")\n"
      ],
      "metadata": {
        "id": "LMRn8-vYdEaE"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip install sqlalchemy\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AXLXCctTdIBd",
        "outputId": "0c12b8df-fa9b-45ea-b471-abb6ed0ef0e9"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sqlalchemy in /usr/local/lib/python3.11/dist-packages (2.0.41)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy) (3.2.3)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy) (4.14.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python daily_loader.py\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hDQH0RgYdLC8",
        "outputId": "82167ea0-3b9f-40ad-ae99-7bc94d6f6506"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Truncated CUST_MSTR\n",
            "✅ Loaded CUST_MSTR_20191112.csv into CUST_MSTR\n",
            "✅ Truncated master_child\n",
            "✅ Loaded master_child_export-20191112.csv into master_child\n",
            "✅ Truncated H_ECOM_Orders\n",
            "✅ Loaded H_ECOM_ORDER.csv into H_ECOM_Orders\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oVA4EUn7dONA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}